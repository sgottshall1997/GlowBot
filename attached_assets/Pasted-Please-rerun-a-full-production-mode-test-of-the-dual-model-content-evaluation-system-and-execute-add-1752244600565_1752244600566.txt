Please rerun a full production-mode test of the dual-model content evaluation system and execute additional test cases to ensure maximum reliability. The goals are to confirm:

✅ Every piece of content is:
  - Generated successfully
  - Evaluated by both ChatGPT and Claude
  - Stored properly in the contentEvaluations table with metadata
  - Linked to contentHistory
  - Sent through webhooks **only after** valid ratings are attached
  - Webhook payload includes the full 36-field schema with `ratings.gpt` and `ratings.claude`

🔁 Step-by-step instructions:

1. **Baseline Test**:
   - Rerun the full 7-niche scheduled generator (simulate or use test mode)
   - Confirm:
     - Exactly 7 unique niche entries
     - All have both GPT + Claude evaluations
     - No duplicates
     - Webhooks were called only *after* evaluations were completed
     - Payloads were received by Make.com with full fields and rating blocks

2. **Edge Case Tests**:
   a. **Empty Script Edge Case**:
      - Simulate generation of a blank or single-word script
      - Confirm models still return scores and justifications
      - Verify webhook is suppressed or flagged if scores are missing

   b. **Extremely Long Script**:
      - Generate a script >1500 characters
      - Ensure evaluation still completes
      - Verify webhook handles long captions without truncation or failure

   c. **Model Mismatch Test**:
      - Force Claude to fail or timeout
      - Ensure the system blocks the webhook and logs the reason
      - Confirm retry or fallback logic is triggered (if applicable)

   d. **Score Conflict Case**:
      - Manually trigger a script expected to be rated high by GPT and low by Claude
      - Confirm score divergence is logged and reflected in the webhook payload

3. **Validation**:
   - For each content test:
     - Check database for:
       - `contentEvaluations` entry with accurate model source, scores, and timestamps
       - Proper linkage to `contentHistory` entry by content ID
     - Confirm webhook payload contains:
       - `ratings.gpt` and `ratings.claude` blocks
       - Accurate average score (if calculated)

4. **Report Summary**:
   - Return a markdown-formatted test report including:
     - Test case name
     - Pass/fail status
     - Score summary (GPT vs Claude)
     - Payload validation result
     - Any issues or anomalies with links to logs

If any test fails, log the issue clearly and halt webhook delivery for that content. Ensure the system is airtight across production and test environments.